# ============================================================================
# DEPLOYMENT CONFIGURATION TEMPLATE
# ============================================================================
# Copy this file to config.env and customize for your organization
# DO NOT commit config.env to git (contains org-specific values)
#
# Usage:
#   cp config.env.example config.env
#   nano config.env  # Edit values
#   source config.env
#   ./scripts/deploy-all.sh
#

# ============================================================================
# ORGANIZATION INFORMATION
# ============================================================================

# Organization name (used in labels and monitoring)
ORG_NAME="example-org"

# Organization base domain (used for LI service domains)
# This is typically your company's base domain without subdomains
ORG_DOMAIN="example.com"

# Deployment environment (prod, staging, dev)
ENVIRONMENT="prod"

# ============================================================================
# DOMAIN CONFIGURATION
# ============================================================================

# Main Matrix homeserver domain
# Users will have IDs like @user:MATRIX_DOMAIN
MATRIX_DOMAIN="matrix.example.com"

# Element Web domain (client interface)
ELEMENT_DOMAIN="chat.example.com"

# Synapse Admin domain (for LI access to admin panel)
ADMIN_DOMAIN="admin.example.com"

# TURN server domain for WebRTC voice/video calls
# CRITICAL: Must be externally reachable by clients (not internal k8s DNS)
# coturn uses hostNetwork:true, so configure DNS for this domain to point to your node IPs
TURN_DOMAIN="turn.matrix.example.com"

# LiveKit domain for video conferencing (WebSocket endpoint)
LIVEKIT_DOMAIN="livekit.matrix.example.com"

# NOTE: Main instance does NOT have Synapse Admin (only LI has it)
# Admin API is available at /_synapse/admin/ on the main Synapse
# See li-instance/ for Synapse Admin LI

# LI Instance domains (lawful intercept environment)
# ============================================================================
# CRITICAL DOMAIN RULES:
#   - LI_SYNAPSE_DOMAIN: SAME as main (required for Matrix authentication)
#   - LI_ELEMENT_DOMAIN: DIFFERENT from main (LI-specific web client)
#   - LI_ADMIN_DOMAIN: DIFFERENT from main (LI-specific admin interface)
#   - LI_KEY_VAULT_DOMAIN: DIFFERENT from main (E2EE key recovery)
#
# LI admins must configure their DNS (hosts file or LI network DNS) to:
#   1. Resolve LI_SYNAPSE_DOMAIN to nginx-li LoadBalancer IP (not main!)
#   2. Resolve LI_ELEMENT_DOMAIN to nginx-li LoadBalancer IP
#   3. Resolve LI_ADMIN_DOMAIN to nginx-li LoadBalancer IP
#   4. Resolve LI_KEY_VAULT_DOMAIN to nginx-li LoadBalancer IP
#
# See li-instance/README.md for detailed DNS configuration instructions
# ============================================================================
LI_SYNAPSE_DOMAIN="${MATRIX_DOMAIN}"             # SAME as main (for user authentication)
LI_ELEMENT_DOMAIN="chat-li.${ORG_DOMAIN}"        # DIFFERENT - LI web client
LI_ADMIN_DOMAIN="admin-li.${ORG_DOMAIN}"         # DIFFERENT - LI admin interface
LI_KEY_VAULT_DOMAIN="keyvault.${ORG_DOMAIN}"     # DIFFERENT - E2EE key recovery

# ============================================================================
# SCALING PARAMETERS
# ============================================================================

# Expected concurrent users (100, 1000, 5000, 10000, 20000)
# Used to calculate resource allocations and replica counts
EXPECTED_CCU=1000

# Synapse worker replica counts (calculated based on CCU)
# Guidelines:
#   100 CCU: synchrotron=2, generic=2, event-persister=2
#   1K CCU: synchrotron=4, generic=4, event-persister=2
#   5K CCU: synchrotron=8, generic=6, event-persister=3
#   10K CCU: synchrotron=12, generic=8, event-persister=4
#   20K CCU: synchrotron=16, generic=10, event-persister=4

REPLICAS_SYNCHROTRON=4
REPLICAS_GENERIC_WORKER=4
REPLICAS_EVENT_PERSISTER=2
REPLICAS_FEDERATION_SENDER=2
REPLICAS_MEDIA_REPOSITORY=2
REPLICAS_TYPING_WRITER=2
REPLICAS_TODEVICE_WRITER=2
REPLICAS_RECEIPTS_WRITER=2
REPLICAS_PRESENCE_WRITER=2

# PostgreSQL configuration
POSTGRESQL_REPLICAS=3  # HA: 3 replicas (1 primary + 2 replicas)
POSTGRESQL_STORAGE_SIZE="100Gi"  # 100 CCU: 50Gi, 1K: 100Gi, 5K: 200Gi, 10K: 500Gi, 20K: 1Ti

# Redis Sentinel configuration
REDIS_REPLICAS=3  # HA: 3 replicas (1 primary + 2 replicas)
REDIS_SENTINEL_REPLICAS=3  # Sentinel quorum: 3 sentinels

# MinIO distributed storage
MINIO_SERVERS=4  # Minimum 4 for EC:4 erasure coding
MINIO_VOLUMES_PER_SERVER=2  # 2 volumes per server = 8 total drives
MINIO_STORAGE_SIZE="500Gi"  # Per volume. 100 CCU: 200Gi, 1K: 500Gi, 5K: 1Ti, 10K: 2Ti

# ============================================================================
# RESOURCE LIMITS
# ============================================================================

# Synapse main process
SYNAPSE_MAIN_CPU_REQUEST="2000m"
SYNAPSE_MAIN_CPU_LIMIT="4000m"
SYNAPSE_MAIN_MEMORY_REQUEST="4Gi"
SYNAPSE_MAIN_MEMORY_LIMIT="8Gi"

# Synapse workers (per pod)
SYNAPSE_WORKER_CPU_REQUEST="500m"
SYNAPSE_WORKER_CPU_LIMIT="2000m"
SYNAPSE_WORKER_MEMORY_REQUEST="1Gi"
SYNAPSE_WORKER_MEMORY_LIMIT="2Gi"

# PostgreSQL (per pod)
POSTGRESQL_CPU_REQUEST="2000m"
POSTGRESQL_CPU_LIMIT="4000m"
POSTGRESQL_MEMORY_REQUEST="4Gi"
POSTGRESQL_MEMORY_LIMIT="8Gi"

# Redis (per pod)
REDIS_CPU_REQUEST="500m"
REDIS_CPU_LIMIT="1000m"
REDIS_MEMORY_REQUEST="2Gi"
REDIS_MEMORY_LIMIT="4Gi"

# ============================================================================
# KUBERNETES CONFIGURATION
# ============================================================================

# Namespace for main instance
NAMESPACE_MAIN="matrix"

# Namespace for LI instance (same as main, isolation via labels)
NAMESPACE_LI="matrix"  # LI runs in same namespace, isolated by NetworkPolicy labels

# Storage class for persistent volumes
# Use appropriate storage class for your cluster (local-path, nfs, ceph, etc.)
STORAGE_CLASS="local-path"

# ============================================================================
# FEATURE FLAGS
# ============================================================================

# Enable federation (true/false)
# Default: false (per CLAUDE.md Section 12)
ENABLE_FEDERATION="false"

# Enable LI (lawful intercept) instance (true/false)
ENABLE_LI="true"

# Enable monitoring stack (Prometheus, Grafana) (true/false)
ENABLE_MONITORING="true"

# Enable HPA for eligible workers (true/false)
# Only applies to synchrotron and generic-worker (Deployments)
ENABLE_HPA="false"

# ============================================================================
# BACKUP CONFIGURATION
# ============================================================================

# Backup server hostname or IP
BACKUP_SERVER="backup.internal.example.com"

# Backup schedule (cron format)
# Default: Daily at 2 AM UTC
BACKUP_SCHEDULE="0 2 * * *"

# Backup retention days
BACKUP_RETENTION_DAYS=30

# ============================================================================
# SECURITY CONFIGURATION
# ============================================================================

# TLS certificate mode for initial deployment
# Uses Let's Encrypt for automatic certificate provisioning during setup
#
# Per CLAUDE.md 4.5: Initial deployment uses Let's Encrypt with cert-manager.
# Certificate renewal after deployment is the organization's responsibility.
#
# Options:
#   letsencrypt-prod - Production Let's Encrypt certificates (default)
#   letsencrypt-staging - Staging certificates for testing (higher rate limits)
TLS_MODE="letsencrypt-prod"

# Network policies enabled (true/false)
# Enables zero-trust security with NetworkPolicy objects
ENABLE_NETWORK_POLICIES="true"

# ============================================================================
# LI CONFIGURATION (Lawful Intercept)
# ============================================================================

# Maximum concurrent sessions per user
# Applies to ALL users without exception
# Recommended: 5-10 for typical deployments
MAX_SESSIONS_PER_USER=5

# Endpoint protection (prevent users from forgetting rooms or deactivating accounts)
# true: Only admins can forget rooms or deactivate accounts
# false: Users can forget rooms and deactivate their own accounts
LI_ENDPOINT_PROTECTION="true"

# ============================================================================
# ADVANCED CONFIGURATION
# ============================================================================

# PostgreSQL connection pool size per worker
# Total connections = (workers x cp_max) + main process connections
# Must stay under PostgreSQL max_connections (default 500)
# Conservative: 10, Moderate: 20, Aggressive: 30
POSTGRESQL_CP_MAX=10

# Synapse cache factor (multiplier for cache sizes)
# Higher values = more memory usage, better performance
# Default: 2.0 for production
CACHE_FACTOR="2.0"

# Event cache size
# Higher values = more memory, fewer database queries
# Default: 50K for production
EVENT_CACHE_SIZE="50K"

# ============================================================================
# ANTIVIRUS CONFIGURATION
# ============================================================================

# Content scanner pickle key (for encrypted media support)
# Generate with: openssl rand -hex 32
CONTENT_SCANNER_PICKLE_KEY="CHANGEME_CONTENT_SCANNER_PICKLE_KEY"

# ============================================================================
# LIVEKIT / ELEMENT CALL CONFIGURATION
# ============================================================================

# Enable LiveKit for group video calls (true/false)
# If false, only 1-on-1 WebRTC calls via coturn will work
ENABLE_LIVEKIT="true"

# LiveKit API credentials
# Generate API key: openssl rand -hex 16
# Generate API secret: openssl rand -base64 32
LIVEKIT_API_KEY="CHANGEME_LIVEKIT_API_KEY"
LIVEKIT_API_SECRET="CHANGEME_LIVEKIT_API_SECRET"

# LiveKit region (for multi-region deployments)
LIVEKIT_REGION="default"

# ============================================================================
# KEY_VAULT CONFIGURATION (LI E2EE Recovery Key Storage)
# ============================================================================

# Django secret key for key_vault application
# Generate with: python -c 'from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())'
# Or: openssl rand -base64 50
KEY_VAULT_DJANGO_SECRET="CHANGEME_KEY_VAULT_DJANGO_SECRET"

# API key for Synapse to communicate with key_vault
# Generate with: openssl rand -hex 32
KEY_VAULT_API_KEY="CHANGEME_KEY_VAULT_API_KEY"

# RSA private key file path for key_vault encryption
# Generate with: openssl genrsa -out key_vault_private.pem 2048
# Store securely and reference path here
KEY_VAULT_RSA_KEY_PATH="./secrets/key_vault_private.pem"

# ============================================================================
# NODE LABELING (Required for dedicated servers)
# ============================================================================

# Monitoring server node name (will be labeled with monitoring=true)
# Per CLAUDE.md Section 6.2: monitoring must run on a DEDICATED server
MONITORING_NODE="monitoring-server-01"

# LiveKit nodes (comma-separated, will be labeled with livekit=true)
# These nodes run LiveKit DaemonSet with hostNetwork for WebRTC
LIVEKIT_NODES="livekit-01,livekit-02,livekit-03,livekit-04"

# ============================================================================
# IMAGE REGISTRY CONFIGURATION
# ============================================================================

# Private registry for container images (if using internal registry)
# Leave empty to use public registries
# Example: registry.internal.example.com/matrix
PRIVATE_REGISTRY=""

# Image pull secret name (if private registry requires authentication)
# Create with: kubectl create secret docker-registry regcred --docker-server=...
IMAGE_PULL_SECRET=""

# ============================================================================
# COTURN TURN SERVER
# ============================================================================

# TURN shared secret (must match Synapse configuration)
# Generate with: openssl rand -base64 32
TURN_SHARED_SECRET="CHANGEME_TURN_SHARED_SECRET"

# TURN external IP (leave empty to use Kubernetes node IP)
# For intranet deployments, empty/auto is correct
# Set manually if nodes have multiple network interfaces
TURN_EXTERNAL_IP=""

# ============================================================================
# NOTES
# ============================================================================
# After editing:
# 1. Copy to config.env: cp config.env.example config.env
# 2. Edit config.env with your values: nano config.env
# 3. Source this file: source config.env
# 4. Run deployment: ./scripts/deploy-all.sh
# 5. Verify: kubectl get pods -n matrix
#
# CRITICAL REQUIREMENTS:
# - Storage class MUST exist: kubectl get storageclass
# - Monitoring node MUST be labeled: kubectl label node <node> monitoring=true
# - Replace ALL CHANGEME values before deployment
#
# IMPORTANT: Add config.env to .gitignore to prevent committing org-specific values
