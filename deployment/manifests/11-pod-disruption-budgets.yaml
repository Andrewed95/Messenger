# Pod Disruption Budgets (PDBs) for High Availability
# Ensures minimum number of pods remain available during voluntary disruptions
# (node drains, cluster upgrades, scaling operations)
#
# PDBs protect against:
# - kubectl drain (node maintenance)
# - Cluster autoscaler scale-down
# - Rolling updates gone wrong
# - Manual scaling down
#
# PDBs do NOT protect against:
# - Node failures (involuntary disruptions)
# - Pod crashes
# - Out of memory kills

---
# ============================================================================
# SYNAPSE WORKERS - Pod Disruption Budgets
# ============================================================================

# Synapse Sync Workers
# Most critical for user experience - handle /sync endpoint
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: synapse-sync-worker
  namespace: matrix
spec:
  # For 100 CCU (2 replicas): minAvailable=1 (50%)
  # For 1K CCU (4 replicas): minAvailable=2 (50%)
  # For 5K CCU (8 replicas): minAvailable=4 (50%)
  # For 10K CCU (12 replicas): minAvailable=6 (50%)
  # For 20K CCU (18 replicas): minAvailable=9 (50%)
  minAvailable: 4  # Adjust based on your scale
  selector:
    matchLabels:
      app: synapse
      component: sync-worker

---
# Synapse Generic Workers
# Handle client API, federation receiver, media
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: synapse-generic-worker
  namespace: matrix
spec:
  # For 100 CCU (2 replicas): minAvailable=1
  # For 1K CCU (2 replicas): minAvailable=1
  # For 5K CCU (4 replicas): minAvailable=2
  # For 10K CCU (6 replicas): minAvailable=3
  # For 20K CCU (8 replicas): minAvailable=4
  minAvailable: 2  # Adjust based on your scale
  selector:
    matchLabels:
      app: synapse
      component: generic-worker

---
# Synapse Event Persisters
# Critical for database write performance
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: synapse-event-persister
  namespace: matrix
spec:
  # Always keep at least 1 available
  # These are critical for write performance
  minAvailable: 1
  selector:
    matchLabels:
      app: synapse
      component: event-persister

---
# Synapse Federation Senders
# Handle outbound federation traffic
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: synapse-federation-sender
  namespace: matrix
spec:
  # For 100 CCU (2 replicas): minAvailable=1
  # For 5K CCU (4 replicas): minAvailable=2
  # For 10K CCU (6 replicas): minAvailable=3
  # For 20K CCU (8 replicas): minAvailable=4
  minAvailable: 2  # Adjust based on your scale
  selector:
    matchLabels:
      app: synapse
      component: federation-sender

---
# ============================================================================
# FRONTEND COMPONENTS - Pod Disruption Budgets
# ============================================================================

# Element Web
# User-facing web client
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: element-web
  namespace: matrix
spec:
  # Keep at least 1 available for serving static files
  minAvailable: 1
  selector:
    matchLabels:
      app: element-web

---
# Synapse Admin
# Admin interface (low traffic)
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: synapse-admin
  namespace: matrix
spec:
  # Allow disruption of all but 1 replica
  # Admin interface can tolerate brief unavailability
  maxUnavailable: 1
  selector:
    matchLabels:
      app: synapse-admin

---
# ============================================================================
# COTURN - Pod Disruption Budgets
# ============================================================================

# coturn TURN/STUN Servers
# Handle NAT traversal for voice/video calls
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: coturn
  namespace: matrix
spec:
  # Keep at least 1 available for new call setup
  # Active calls on disrupted pods will fail (stateful connections)
  # But new calls can use remaining pods
  minAvailable: 1
  selector:
    matchLabels:
      app: coturn

---
# ============================================================================
# REDIS - Pod Disruption Budgets
# ============================================================================

# Redis Sentinel
# Manages Redis HA cluster (3 nodes required for quorum)
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: redis-synapse-node
  namespace: matrix
spec:
  # CRITICAL: Redis Sentinel requires quorum of 2 out of 3
  # Must keep at least 2 available to maintain quorum
  minAvailable: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: redis
      app.kubernetes.io/instance: redis-synapse

---
# Redis Sentinel for LiveKit
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: redis-livekit-node
  namespace: livekit
spec:
  # Same as above - maintain quorum
  minAvailable: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: redis
      app.kubernetes.io/instance: redis-livekit

---
# ============================================================================
# POSTGRESQL - Pod Disruption Budget
# ============================================================================

# PostgreSQL Cluster (CloudNativePG)
# Note: CloudNativePG operator manages its own PDB automatically
# This is a backup/additional PDB for extra protection
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: postgresql-cluster
  namespace: matrix
spec:
  # For 3-replica cluster: minAvailable=2 (maintains quorum)
  # For 5-replica cluster: minAvailable=3 (maintains quorum)
  # This ensures we can still elect a new primary during maintenance
  minAvailable: 2
  selector:
    matchLabels:
      cnpg.io/cluster: matrix-postgresql

---
# ============================================================================
# LIVEKIT - Pod Disruption Budget
# ============================================================================

# LiveKit SFU Server
# Handles group video conferencing
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: livekit
  namespace: livekit
spec:
  # Keep at least 1 available for new video rooms
  # Active rooms on disrupted pods will fail (stateful video sessions)
  # But new rooms can be created on remaining pods
  minAvailable: 1
  selector:
    matchLabels:
      app: livekit

---
# ============================================================================
# NOTES ON CONFIGURATION
# ============================================================================
#
# 1. SCALING YOUR PDBs:
#    When you scale worker replicas, update minAvailable accordingly.
#    Rule of thumb: minAvailable = 50% of replicas (rounded up)
#
#    Example for sync workers at 20K CCU (18 replicas):
#    minAvailable: 9  # Allows draining 9 pods, keeps 9 running
#
# 2. USING maxUnavailable INSTEAD:
#    You can use maxUnavailable instead of minAvailable:
#    - minAvailable: 4 = "keep at least 4 running"
#    - maxUnavailable: 2 = "can disrupt at most 2"
#
#    maxUnavailable is better when replica count changes often.
#
# 3. PERCENTAGE-BASED VALUES:
#    You can use percentages instead of absolute numbers:
#    minAvailable: 50%  # Keep at least 50% running
#    maxUnavailable: 25%  # Can disrupt at most 25%
#
#    This auto-scales with replica count!
#
# 4. TESTING YOUR PDBs:
#    # Check PDB status
#    kubectl get pdb -n matrix
#
#    # Try to drain a node (will respect PDBs)
#    kubectl drain <node-name> --ignore-daemonsets
#
#    # If PDB prevents drain, you'll see:
#    # "Cannot evict pod as it would violate the pod's disruption budget"
#
# 5. PDB LIMITATIONS:
#    - Only protects against VOLUNTARY disruptions
#    - Does NOT protect against node failures or pod crashes
#    - Does NOT prevent forced operations (kubectl delete pod --force)
#
# 6. MINIMUM REPLICAS:
#    PDBs only work if you have multiple replicas!
#    Components with replicas: 1 don't need PDBs:
#    - Synapse Main (singleton by design)
#    - MinIO Console (not critical path)
#
# ============================================================================
